# Decision Tree Classification and Ensemble Methods: Practical Assignment

This assignment is aimed at constructing and evaluating classifiers using **Decision Tree** classification and its ensemble variants: **Bagging** and **AdaBoost**. The performance of these classifiers is evaluated and compared on two datasets, and additional evaluation is conducted across 10 datasets for comprehensive comparison.

---

## Assignment Tasks

### 1. Decision Tree Classification on Two Datasets

- **Objective**: 
  - Use the **Decision Tree Classification** algorithm to build classifiers on two datasets.
  - Split each dataset into a **training set (75%)** and a **test set (25%)**.
  - Evaluate and compare the classifier's performance using the following ensemble methods:
    - **Bagging Ensemble** with 3, 5, 7, and 9 Decision Tree classifiers.
    - **AdaBoost Ensemble** with 3, 5, 7, and 9 Decision Tree classifiers.
- **Evaluation Metrics**: Accuracy, Precision, Recall, and F1-Score.
  
### 2. Performance Comparison Across 10 Datasets

- **Objective**: 
  - Compare the performance of **Decision Tree**, **Bagging Ensemble**, **AdaBoost Ensemble**, and **Random Forest** classifiers on 10 datasets (from Table 6.5 in the assignment).
  - Display the performance metrics (accuracy, precision, recall, F1-score) for all classifiers and datasets in a tabular format.
  
- **Ensemble Parameters**:
  - **Bagging**: Use 3, 5, 7, and 9 Decision Tree classifiers.
  - **AdaBoost**: Use 3, 5, 7, and 9 Decision Tree classifiers.
  - **Random Forest**: Default parameters with 100 estimators.

---
